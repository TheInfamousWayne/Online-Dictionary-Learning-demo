{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning Demo\n",
    "#### Simple pytorch implementation of a Dictionary Learning demo employing stochastic gradient descent, on MNIST. \n",
    "\n",
    "See Readme.me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages and Defining hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import time\n",
    "import importlib\n",
    "import src.dataloader as D\n",
    "from torchvision import transforms\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "import ipdb\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 50\n",
    "BATCH_SIZE = 1000\n",
    "LR = .5  # learning rate\n",
    "MNT = 0.9   # momentum variable\n",
    "DOWNLOAD_Dataset = False\n",
    "N_TEST_IMG = 5\n",
    "dictionary_size = 250     # Dictionary Size\n",
    "\n",
    "hyperparameters = {\n",
    "        \"K\": dictionary_size,\n",
    "        \"m\": 100000,  # number of sub_patch images of size (filter_size x filter_size)\n",
    "        \"filter_size\": 16,\n",
    "        \"eps\": 0.1,\n",
    "        \"n_channels\": 1,  # 1 when grayscale\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and importing training and testing data - using MNIST digits for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vagrawal/Projects/MaLTT/data/slides/02B_H&E_Control.jpeg\n",
      "mean var done\n",
      "normalisation done\n"
     ]
    }
   ],
   "source": [
    "# train_data = torchvision.datasets.MNIST(\n",
    "#     root='../data',\n",
    "#     train=True,                                     # this is training data\n",
    "#     transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "#                               torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#                              ]),    \n",
    "#     download=DOWNLOAD_Dataset,                        # download it if you don't have it\n",
    "# )\n",
    "# # Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# \n",
    "# test_data = torchvision.datasets.MNIST(\n",
    "#     root='../data',\n",
    "#     train=False,                                     # this is testing data\n",
    "#     transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "#                               torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#                              ]),\n",
    "#     download=DOWNLOAD_Dataset,                        # download it if you don't have it\n",
    "# )\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([D.ToTensor()])\n",
    "dict_dataset = D.DictionaryDatasetSingleImage(img_path='/home/vagrawal/Projects/MaLTT/data/slides/02B_H&E_Control.jpeg',\n",
    "                                               hyperparameters=hyperparameters,\n",
    "                                               transform=data_transform)\n",
    "dataloader = D.DataLoader(dict_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary model, as well as the dictionary learning method, is defined in Simple_DL.py file.\n",
    "Here the model is initialized, we define the optimizer and the loss function to be the $\\ell_2$ loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Dictionary_Model' from '/home/vagrawal/Projects/MaLTT/Online-Dictionary-Learning-demo/Dictionary_Model.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import importlib\n",
    "# importlib.reload(modelDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dictionary_Model as modelDL\n",
    "\n",
    "n_features = hyperparameters['filter_size']**2 * hyperparameters['n_channels']\n",
    "model = modelDL.DictLearn(dictionary_size, n_features).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MNT)\n",
    "loss_func = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(modelDL)\n",
    "\n",
    "# Training\n",
    "Error = np.zeros((EPOCH,))\n",
    "Nnz = np.zeros((EPOCH,))\n",
    "Loss = np.zeros((EPOCH,))\n",
    "N = len(dict_dataset)\n",
    "DISPLAY_FREQ = 1 ; \n",
    "TSHOW = np.round(DISPLAY_FREQ * N/BATCH_SIZE) # times per EPOCH to display information\n",
    "t0 = time.perf_counter()\n",
    "SC = 'IHT' # 'fista' or 'IHT'\n",
    "K = 1       # sparsity parameter: float numer if 'fista' or cardinality constraint if 'IHT'\n",
    "\n",
    "Err = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.10837455410103\n",
      "77.04456047811199\n",
      "51.689893367553516\n",
      "39.01261264939267\n",
      "31.406236084252225\n",
      "26.335320742805436\n",
      "22.713229948955725\n",
      "19.996680726341896\n",
      "17.883774539158093\n",
      "16.193477336080992\n",
      "14.810518305081258\n",
      "13.658027426760393\n",
      "12.682859377202778\n",
      "11.846990644650786\n",
      "11.122562143518172\n",
      "10.48868441606921\n",
      "9.929383322286654\n",
      "9.43223729374457\n",
      "8.98743492284851\n",
      "8.587111846716615\n",
      "8.224905530372492\n",
      "7.895640814306299\n",
      "7.59500310477422\n",
      "7.319410401893243\n",
      "7.065858332828699\n",
      "6.831804798397879\n",
      "6.615102073545762\n",
      "6.413869893263586\n",
      "6.226536124218114\n",
      "6.0516720314137205\n",
      "5.888091524059877\n",
      "5.734738038377473\n",
      "5.590675752738815\n",
      "5.455096665244242\n",
      "5.327263050113527\n",
      "5.20652756426689\n",
      "5.09231590585777\n",
      "4.984120521100726\n",
      "4.8814653427695225\n",
      "4.78394333546875\n",
      "4.69118002914741\n",
      "4.60283581778062\n",
      "4.518600391155187\n",
      "4.438191918771239\n",
      "4.361358723015182\n",
      "4.2878617809288\n",
      "4.21749931461078\n",
      "4.150057835443191\n",
      "4.085376084855798\n",
      "4.023283479596749\n",
      "3.9636313883450796\n",
      "3.9062684540574426\n",
      "3.8510642175277887\n",
      "3.7979131242099915\n",
      "3.746686711732285\n",
      "3.6972945430528013\n",
      "3.649631116305564\n",
      "3.60361240730064\n",
      "3.5591601846047682\n",
      "3.516179887436998\n",
      "3.4746068881176373\n",
      "3.434385978820891\n",
      "3.3954359091409874\n",
      "3.35770493481604\n",
      "3.321137716657915\n",
      "3.285681966097535\n",
      "3.2512798067359854\n",
      "3.217883303952709\n",
      "3.185459040568763\n",
      "3.153963297985751\n",
      "3.123350813813631\n",
      "3.093593122359987\n",
      "3.0646502803177307\n",
      "3.0364901317621142\n",
      "3.009079612467547\n",
      "2.9823887723065723\n",
      "2.956395880453636\n",
      "2.93106731154975\n",
      "2.906377204608282\n",
      "2.882304170678666\n",
      "2.858827512663288\n",
      "2.8359221832106147\n",
      "2.8135695357305126\n",
      "2.7917500888798767\n",
      "2.770445792048442\n",
      "2.749636747167915\n",
      "2.729303168088745\n",
      "2.709428206203242\n",
      "2.690001475513762\n",
      "2.671010857687943\n",
      "2.652437902646849\n",
      "2.6342692022512595\n",
      "2.6164884419812577\n",
      "2.5990850963921046\n",
      "2.5820472491832995\n",
      "2.5653637528417734\n",
      "2.54902881897131\n",
      "2.533026034374507\n",
      "2.517346772640289\n",
      "2.5019773573188373\n",
      "Epoch:  0 , Error:  2.5019773573188373 , | train loss: 2.455e+00  NNZ/(1-sparsity):  0.010200000000000008\n",
      "0.9799754947498195\n",
      "0.9802302020589683\n",
      "0.9801970171210259\n",
      "0.9802132117457346\n",
      "0.9802577711234439\n",
      "0.9802242371724087\n",
      "0.9802667993477796\n",
      "0.9802648867478972\n",
      "0.9802931870870508\n",
      "0.9802565585304732\n",
      "0.9802112389546818\n",
      "0.980226698650331\n",
      "0.9802199248318253\n",
      "0.9802147304062291\n",
      "0.980181341220295\n",
      "0.9801524258190751\n",
      "0.9801200288867691\n",
      "0.9801491827706558\n",
      "0.9801364643963614\n",
      "0.98014107350209\n",
      "0.9801479312683954\n",
      "0.9801511383993158\n",
      "0.9801456951500633\n",
      "0.9801342424976\n",
      "0.980120913930456\n",
      "0.9801285106610677\n",
      "0.9801326982919283\n",
      "0.9801342619874279\n",
      "0.9801276675880312\n",
      "0.9801209867481956\n",
      "0.9801269677175243\n",
      "0.9801181757630787\n",
      "0.9801287326451383\n",
      "0.980133601282311\n",
      "0.9801281589722868\n",
      "0.9801238073440361\n",
      "0.9801169835455933\n",
      "0.9801138348925054\n",
      "0.9801136784989896\n",
      "0.9801179680761569\n",
      "0.9801205191525507\n",
      "0.9801165519808974\n",
      "0.980115578909713\n",
      "0.9801170801338269\n",
      "0.9801215903947805\n",
      "0.9801207260134643\n",
      "0.9801327580863262\n",
      "0.980126381723557\n",
      "0.980132739470868\n",
      "0.9801313583282532\n",
      "0.9801325999379158\n",
      "0.9801283966093581\n",
      "0.9801272462235212\n",
      "0.9801210780852685\n",
      "0.9801103998320737\n",
      "0.9801093974977952\n",
      "0.9801082610505233\n",
      "0.9801068597078164\n",
      "0.9801019831427819\n",
      "0.980100483298424\n",
      "0.9800997009241611\n",
      "0.9800937049263668\n",
      "0.9800946879669163\n",
      "0.9800917008181109\n",
      "0.9800888682020849\n",
      "0.9800923432989664\n",
      "0.9800930801699052\n",
      "0.980096089667784\n",
      "0.9800933594867124\n",
      "0.9800965769067239\n",
      "0.9800956976666669\n",
      "0.9800985114205023\n",
      "0.9800953869213329\n",
      "0.9800974048656809\n",
      "0.9800974896399959\n",
      "0.9800987037267849\n",
      "0.9800978944220978\n",
      "0.9800975535320404\n",
      "0.9800964266173198\n",
      "0.9800947035599374\n",
      "0.9800943237770549\n",
      "0.9800897206641496\n",
      "0.9800903954191487\n",
      "0.9800853667103878\n",
      "0.9800843049909667\n",
      "0.9800829108246382\n",
      "0.980078475200976\n",
      "0.980079879953223\n",
      "0.9800778939952\n",
      "0.9800759873287529\n",
      "0.9800775158127191\n",
      "0.9800742449222731\n",
      "0.9800708855044705\n",
      "0.9800692860286059\n",
      "0.9800669579627473\n",
      "0.9800658960187193\n",
      "0.9800675637543546\n",
      "0.9800657146077446\n",
      "0.9800617323685706\n",
      "0.9800593593544565\n",
      "Epoch:  1 , Error:  0.9800593593544565 , | train loss: 9.605e-01  NNZ/(1-sparsity):  0.004000000000000003\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    for step, sample in enumerate(dataloader):\n",
    "        x = sample['image']\n",
    "        b_x = (x.view(x.shape[0], -1)).double().to(device)   # batch x, shape (batch, 28*28)\n",
    "        \n",
    "        b_y = b_x.clone()\n",
    "\n",
    "        decoded, encoded, errIHT = model(b_x, SC, K)\n",
    "        \n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        if SC == 'IHT': Loss[epoch] = Loss[epoch] + loss.data.item()\n",
    "        elif SC == 'fista': Loss[epoch] = Loss[epoch] + loss.data.item() + K * np.sum(np.abs(encoded.cpu().numpy()))\n",
    "        decoded = decoded.detach()\n",
    "        err = np.linalg.norm( (decoded-b_x).cpu().numpy() ,'fro') / np.linalg.norm( b_x.cpu().numpy() ,'fro')\n",
    "        Error[epoch] = Error[epoch] + errIHT[-1]\n",
    "        Err = np.append(Err,errIHT[-1])\n",
    "        Nnz[epoch] = Nnz[epoch] + np.count_nonzero(encoded.cpu().numpy())/encoded.cpu().numpy().size\n",
    "        \n",
    "#         # for debugging:\n",
    "#         print(Error[epoch]/(step+1))\n",
    "#         if step%50==0:\n",
    "#             plt.plot(errIHT); plt.show()\n",
    "        \n",
    "    Loss[epoch] /= len(dataloader)\n",
    "    Error[epoch] /= (step+1)\n",
    "    Nnz[epoch] /= (step+1)\n",
    "    print('Epoch: ', epoch, ', Error: ', Error[epoch], ', | train loss: %.3e' % Loss[epoch], ' NNZ/(1-sparsity): ', Nnz[epoch] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('dict_learner.pkl', 'wb') as fid:\n",
    "    pickle.dump(model, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(Err); plt.grid(); plt.title('Reconstruction Error'); plt.xlabel('mini-bach / dict update');\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(Loss); plt.grid(); plt.title('Loss Evolution'); plt.xlabel('epoch')\n",
    "plt.show(); \n",
    "plt.savefig(\"reconstruction.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "W = model.cpu().W.data.numpy().copy()\n",
    "\n",
    "M1 = modelDL.showFilters(W,10,20)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(rescale(M1,4,mode='constant'),cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.savefig(\"dict.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dictionary():\n",
    "    with open('dict_learner.pkl', 'rb') as fid:\n",
    "        dict_learner = pickle.load(fid)\n",
    "    return dict_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}